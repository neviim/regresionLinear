{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ataques_Adversarios.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neviim/regresionLinear/blob/master/Ataques_Adversarios.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "L-9CK32nO8QH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://www.youtube.com/watch?v=JoQx39CoXW8"
      ]
    },
    {
      "metadata": {
        "id": "0E_emLkVOQmY",
        "colab_type": "code",
        "outputId": "88d83ca1-33cf-4c8d-dfec-b693799aca77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "p6TjTpKeOmr3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.inception_v3 import InceptionV3, decode_predictions\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "76s2TVIAPPHO",
        "colab_type": "code",
        "outputId": "291f6c52-8196-44bf-8246-47fca385f0b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "iv3 = InceptionV3()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
            "96116736/96112376 [==============================] - 18s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-GhL1YVLPktP",
        "colab_type": "code",
        "outputId": "d8bb543f-4d87-4dc5-d12c-918937c937a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11256
        }
      },
      "cell_type": "code",
      "source": [
        "# este modelo esta pre-trenado \n",
        "print(iv3.summary())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, None, None, 3 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, None, None, 3 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, None, None, 3 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, None, None, 3 9216        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, None, None, 3 96          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, None, None, 3 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, None, None, 6 18432       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, None, None, 6 192         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, None, None, 6 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 6 0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, None, None, 8 5120        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, None, None, 8 240         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, None, None, 8 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, None, None, 1 138240      activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, None, None, 1 576         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, None, None, 1 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 1 0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, None, None, 6 192         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, None, None, 6 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, None, None, 4 9216        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, None, None, 9 55296       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, None, None, 4 144         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, None, None, 9 288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, None, None, 4 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, None, None, 9 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, None, None, 1 0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, None, None, 6 76800       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, None, None, 9 82944       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, None, None, 3 6144        average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, None, None, 6 192         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, None, None, 6 192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, None, None, 9 288         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, None, None, 3 96          conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, None, None, 6 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, None, None, 6 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, None, None, 9 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, None, None, 3 0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, None, None, 2 0           activation_6[0][0]               \n",
            "                                                                 activation_8[0][0]               \n",
            "                                                                 activation_11[0][0]              \n",
            "                                                                 activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, None, None, 6 192         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, None, None, 6 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, None, None, 4 12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, None, None, 9 55296       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, None, None, 4 144         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, None, None, 9 288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, None, None, 4 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, None, None, 9 0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, None, None, 2 0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, None, None, 6 76800       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, None, None, 9 82944       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, None, None, 6 16384       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, None, None, 6 192         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, None, None, 6 192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, None, None, 9 288         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, None, None, 6 192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, None, None, 6 0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, None, None, 6 0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, None, None, 9 0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, None, None, 6 0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, None, None, 2 0           activation_13[0][0]              \n",
            "                                                                 activation_15[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, None, None, 6 192         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, None, None, 6 0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, None, None, 4 13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, None, None, 9 55296       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, None, None, 4 144         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, None, None, 9 288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, None, None, 4 0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, None, None, 9 0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, None, None, 2 0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, None, None, 6 76800       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, None, None, 9 82944       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, None, None, 6 18432       average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, None, None, 6 192         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, None, None, 6 192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, None, None, 9 288         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, None, None, 6 192         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, None, None, 6 0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, None, None, 6 0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, None, None, 9 0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, None, None, 6 0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, None, None, 2 0           activation_20[0][0]              \n",
            "                                                                 activation_22[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "                                                                 activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, None, None, 6 18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, None, None, 6 192         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, None, None, 6 0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, None, None, 9 55296       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, None, None, 9 288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, None, None, 9 0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, None, None, 3 995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, None, None, 9 82944       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, None, None, 3 1152        conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, None, None, 9 288         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, None, None, 3 0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, None, None, 9 0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 2 0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, None, None, 7 0           activation_27[0][0]              \n",
            "                                                                 activation_30[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, None, None, 1 384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, None, None, 1 0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, None, None, 1 114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, None, None, 1 384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, None, None, 1 0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, None, None, 1 114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, None, None, 1 384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, None, None, 1 384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, None, None, 1 0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, None, None, 1 0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, None, None, 1 114688      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, None, None, 1 114688      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, None, None, 1 384         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, None, None, 1 384         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, None, None, 1 0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, None, None, 1 0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, None, None, 7 0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, None, None, 1 147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, None, None, 1 172032      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, None, None, 1 172032      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, None, None, 1 576         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, None, None, 1 576         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, None, None, 1 576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, None, None, 1 576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, None, None, 1 0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, None, None, 1 0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, None, None, 1 0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, None, None, 1 0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, None, None, 7 0           activation_31[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "                                                                 activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, None, None, 1 480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, None, None, 1 0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, None, None, 1 179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, None, None, 1 480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, None, None, 1 0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, None, None, 1 179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, None, None, 1 480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, None, None, 1 480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, None, None, 1 0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, None, None, 1 0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, None, None, 1 179200      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, None, None, 1 179200      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, None, None, 1 480         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, None, None, 1 480         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, None, None, 1 0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, None, None, 1 0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, None, None, 7 0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, None, None, 1 147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, None, None, 1 215040      activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, None, None, 1 215040      activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, None, None, 1 576         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, None, None, 1 576         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, None, None, 1 576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, None, None, 1 576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, None, None, 1 0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, None, None, 1 0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, None, None, 1 0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, None, None, 1 0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, None, None, 7 0           activation_41[0][0]              \n",
            "                                                                 activation_44[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "                                                                 activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, None, None, 1 480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, None, None, 1 0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, None, None, 1 179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, None, None, 1 480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, None, None, 1 0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, None, None, 1 179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, None, None, 1 480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, None, None, 1 480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, None, None, 1 0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, None, None, 1 0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, None, None, 1 179200      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, None, None, 1 179200      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, None, None, 1 480         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, None, None, 1 480         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, None, None, 1 0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, None, None, 1 0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, None, None, 7 0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, None, None, 1 147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, None, None, 1 215040      activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, None, None, 1 215040      activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, None, None, 1 576         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, None, None, 1 576         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, None, None, 1 576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, None, None, 1 576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, None, None, 1 0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, None, None, 1 0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, None, None, 1 0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, None, None, 1 0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, None, None, 7 0           activation_51[0][0]              \n",
            "                                                                 activation_54[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "                                                                 activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, None, None, 1 576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, None, None, 1 0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, None, None, 1 258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, None, None, 1 576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, None, None, 1 0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, None, None, 1 258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, None, None, 1 576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, None, None, 1 576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, None, None, 1 0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, None, None, 1 0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, None, None, 1 258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, None, None, 1 258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, None, None, 1 576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, None, None, 1 576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, None, None, 1 0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, None, None, 1 0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, None, None, 7 0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, None, None, 1 258048      activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, None, None, 1 258048      activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, None, None, 1 576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, None, None, 1 576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, None, None, 1 576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, None, None, 1 576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, None, None, 1 0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, None, None, 1 0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, None, None, 1 0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, None, None, 1 0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, None, None, 7 0           activation_61[0][0]              \n",
            "                                                                 activation_64[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "                                                                 activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, None, None, 1 576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, None, None, 1 0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, None, None, 1 258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, None, None, 1 576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, None, None, 1 0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, None, None, 1 258048      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, None, None, 1 576         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, None, None, 1 576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, None, None, 1 0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, None, None, 1 0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, None, None, 3 552960      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, None, None, 1 331776      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, None, None, 3 960         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, None, None, 1 576         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, None, None, 3 0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, None, None, 1 0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, None, None, 7 0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, None, None, 1 0           activation_72[0][0]              \n",
            "                                                                 activation_76[0][0]              \n",
            "                                                                 max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, None, None, 4 573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, None, None, 4 1344        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, None, None, 4 0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, None, None, 3 491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, None, None, 3 1548288     activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, None, None, 3 1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, None, None, 3 1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, None, None, 3 0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, None, None, 3 0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, None, None, 3 442368      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, None, None, 3 442368      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, None, None, 3 442368      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, None, None, 3 442368      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, None, None, 1 0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, None, None, 3 409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, None, None, 3 1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, None, None, 3 1152        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, None, None, 3 1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, None, None, 3 1152        conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, None, None, 1 245760      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, None, None, 3 960         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, None, None, 3 0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, None, None, 3 0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, None, None, 3 0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, None, None, 3 0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, None, None, 1 576         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, None, None, 3 0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, None, None, 7 0           activation_79[0][0]              \n",
            "                                                                 activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, None, None, 7 0           activation_83[0][0]              \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, None, None, 1 0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, None, None, 2 0           activation_77[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, None, None, 4 917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, None, None, 4 1344        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, None, None, 4 0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, None, None, 3 786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, None, None, 3 1548288     activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, None, None, 3 1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, None, None, 3 1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, None, None, 3 0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, None, None, 3 0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, None, None, 3 442368      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, None, None, 3 442368      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, None, None, 3 442368      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, None, None, 3 442368      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, None, None, 2 0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, None, None, 3 655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, None, None, 3 1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, None, None, 3 1152        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, None, None, 3 1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, None, None, 3 1152        conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, None, None, 1 393216      average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, None, None, 3 960         conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, None, None, 3 0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, None, None, 3 0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, None, None, 3 0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, None, None, 3 0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, None, None, 1 576         conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, None, None, 3 0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, None, None, 7 0           activation_88[0][0]              \n",
            "                                                                 activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, None, None, 7 0           activation_92[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, None, None, 1 0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, None, None, 2 0           activation_86[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_2[0][0]              \n",
            "                                                                 activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 23,851,784\n",
            "Trainable params: 23,817,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1lxgV_MwQHpY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-hIeaQrzQi-r",
        "colab_type": "code",
        "outputId": "70bddaf1-4fcf-46fb-9c1f-aa0e37e5671a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# carrega como um formato de imagem\n",
        "XI = image.load_img(\"./panda.jpg\")\n",
        "\n",
        "# para usar esta imagem no tensorFlow a imagem tem que ter (299 x 299)\n",
        "\n",
        "# ou como uma matrix de valor\n",
        "X = image.img_to_array(image.load_img(\"./tiger.jpg\", target_size=(299, 299))) \n",
        "\n",
        "#print(X)\n",
        "print(X.shape)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(299, 299, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BbfVmn2oXOJ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 840
        },
        "outputId": "0d6b915e-f0b8-429d-d841-424184f06257"
      },
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[161. 184. 190.]\n",
            "  [157. 179. 192.]\n",
            "  [155. 175. 199.]\n",
            "  ...\n",
            "  [ 59.  83.  47.]\n",
            "  [ 23.  51.   0.]\n",
            "  [ 99. 129.  57.]]\n",
            "\n",
            " [[161. 184. 190.]\n",
            "  [157. 179. 192.]\n",
            "  [155. 175. 199.]\n",
            "  ...\n",
            "  [ 59.  83.  47.]\n",
            "  [ 23.  51.   0.]\n",
            "  [ 99. 129.  57.]]\n",
            "\n",
            " [[166. 189. 195.]\n",
            "  [162. 184. 198.]\n",
            "  [159. 179. 203.]\n",
            "  ...\n",
            "  [134. 158. 126.]\n",
            "  [ 42.  69.  14.]\n",
            "  [ 87. 116.  49.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[104. 137.  20.]\n",
            "  [105. 142.   2.]\n",
            "  [146. 188.  18.]\n",
            "  ...\n",
            "  [ 84. 113.   0.]\n",
            "  [ 77. 107.   0.]\n",
            "  [113. 144.  15.]]\n",
            "\n",
            " [[ 87. 116.  24.]\n",
            "  [105. 141.   7.]\n",
            "  [126. 170.   0.]\n",
            "  ...\n",
            "  [ 80. 109.   0.]\n",
            "  [ 74. 103.   0.]\n",
            "  [110. 140.  16.]]\n",
            "\n",
            " [[ 87. 116.  24.]\n",
            "  [105. 141.   7.]\n",
            "  [126. 170.   0.]\n",
            "  ...\n",
            "  [ 80. 109.   0.]\n",
            "  [ 74. 103.   0.]\n",
            "  [110. 140.  16.]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LfGZDCRwWSU-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 840
        },
        "outputId": "344aa9ae-a1d1-4263-ffce-a69cd12fa2bf"
      },
      "cell_type": "code",
      "source": [
        "# print(X)\n",
        "# Alterando os valores da matrix de um ranger de 0-255 para -1 a 1\n",
        "X /= 255\n",
        "X -= 0.5\n",
        "X *= 2\n",
        "\n",
        "print(X)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[-0.9607843  -0.36470586  0.10588241]\n",
            "  [-0.90588236 -0.32549018  0.15294123]\n",
            "  [-0.8980392  -0.31764704  0.16078436]\n",
            "  ...\n",
            "  [ 1.          0.96862745  0.8745098 ]\n",
            "  [ 1.          1.          0.9137255 ]\n",
            "  [ 0.96862745  0.9764706   0.9137255 ]]\n",
            "\n",
            " [[-0.90588236 -0.32549018  0.15294123]\n",
            "  [-0.8666667  -0.2862745   0.19215691]\n",
            "  [-0.8666667  -0.27843136  0.17647064]\n",
            "  ...\n",
            "  [ 1.          1.          0.92156863]\n",
            "  [ 0.9843137   0.99215686  0.92941177]\n",
            "  [ 0.84313726  0.88235295  0.8352941 ]]\n",
            "\n",
            " [[-0.84313726 -0.27843136  0.18431377]\n",
            "  [-0.81960785 -0.25490195  0.20784318]\n",
            "  [-0.8117647  -0.24705881  0.21568632]\n",
            "  ...\n",
            "  [ 0.96862745  1.          0.9607843 ]\n",
            "  [ 0.85882354  0.8980392   0.8666667 ]\n",
            "  [ 0.5294118   0.6         0.5921569 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.64705884  0.7019608   0.7647059 ]\n",
            "  [ 0.6627451   0.7176471   0.78039217]\n",
            "  [ 0.6392157   0.69411767  0.75686276]\n",
            "  ...\n",
            "  [-0.6        -0.19215685  0.09803927]\n",
            "  [-0.60784316 -0.19999999  0.09019613]\n",
            "  [-0.62352943 -0.21568626  0.07450986]]\n",
            "\n",
            " [[ 0.6784314   0.70980394  0.78039217]\n",
            "  [ 0.6862745   0.7176471   0.7882353 ]\n",
            "  [ 0.67058825  0.7019608   0.77254903]\n",
            "  ...\n",
            "  [-0.5921569  -0.18431371  0.10588241]\n",
            "  [-0.6        -0.19215685  0.09803927]\n",
            "  [-0.60784316 -0.21568626  0.07450986]]\n",
            "\n",
            " [[ 0.6862745   0.7176471   0.7882353 ]\n",
            "  [ 0.7019608   0.73333335  0.8039216 ]\n",
            "  [ 0.69411767  0.7254902   0.79607844]\n",
            "  ...\n",
            "  [-0.5764706  -0.18431371  0.09019613]\n",
            "  [-0.58431375 -0.19215685  0.082353  ]\n",
            "  [-0.60784316 -0.21568626  0.05882359]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F08XFkdsXhFv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a278bc96-4b80-41b3-b684-c0be373fbc84"
      },
      "cell_type": "code",
      "source": [
        "# dimensao da rede neural \n",
        "print(X.shape)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(299, 299, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Bsf8X6RcXuve",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "89228f52-d45b-4fdb-e5d2-ffeabc188fbd"
      },
      "cell_type": "code",
      "source": [
        "X = X.reshape([1, X.shape[0], X.shape[1], X.shape[2]])\n",
        "\n",
        "print(X.shape)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 299, 299, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e6b01CbzZhRb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4217
        },
        "outputId": "54bc44d9-6128-46ab-d786-6f9bc0b91c6f"
      },
      "cell_type": "code",
      "source": [
        "Y = iv3.predict(X)\n",
        "\n",
        "print(Y)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5.37046253e-05 9.50236063e-05 1.59809395e-04 1.15415591e-04\n",
            "  5.55137995e-05 3.56290948e-05 4.46134836e-05 6.78796787e-05\n",
            "  5.28989913e-05 3.96032701e-05 8.37111802e-05 3.62876308e-05\n",
            "  3.47281202e-05 5.63036519e-05 5.13624909e-05 1.49843239e-04\n",
            "  6.53054012e-05 7.19952659e-05 3.53939613e-05 6.81893653e-05\n",
            "  7.30447573e-05 3.00578376e-05 7.47743979e-05 2.43199756e-05\n",
            "  9.86977830e-05 8.20704518e-05 4.79314767e-05 9.02673419e-05\n",
            "  1.10881520e-04 9.66855587e-05 1.07402440e-04 8.11057907e-05\n",
            "  5.17176122e-05 1.15623923e-04 1.20742552e-04 8.41583969e-05\n",
            "  9.93895737e-05 1.03450962e-04 7.17171861e-05 6.72394453e-05\n",
            "  3.66071326e-05 4.43251010e-05 3.97343938e-05 7.07016006e-05\n",
            "  7.93145955e-05 4.04451202e-05 7.01479148e-05 3.18831189e-05\n",
            "  4.55308182e-05 7.52163978e-05 1.90293213e-04 7.35843132e-05\n",
            "  5.74785663e-05 4.96387729e-05 2.36478772e-05 9.12940232e-05\n",
            "  7.20839598e-05 7.96591266e-05 1.00945195e-04 4.56999987e-05\n",
            "  2.00720955e-04 9.23355547e-05 7.04925478e-05 3.35124059e-05\n",
            "  7.94328371e-05 6.45459295e-05 6.54777687e-05 8.39333297e-05\n",
            "  2.27446526e-05 4.88049263e-05 3.57251447e-05 1.55874295e-04\n",
            "  2.18896064e-04 8.59656284e-05 2.25146519e-04 9.48293309e-05\n",
            "  7.09123487e-05 1.13790738e-04 3.48991380e-05 7.57960661e-05\n",
            "  4.17557349e-05 5.13339401e-05 4.47585480e-05 3.53079558e-05\n",
            "  3.19426799e-05 1.28855081e-05 4.64085606e-05 3.21854131e-05\n",
            "  9.32149269e-05 2.37390759e-05 7.37218434e-05 4.58160357e-05\n",
            "  3.24198772e-05 3.83642036e-05 1.58492021e-05 6.25487810e-05\n",
            "  3.03307570e-05 7.79180846e-05 3.77832548e-05 1.35162452e-04\n",
            "  1.34077622e-04 9.56234071e-05 3.16693549e-05 7.64156794e-05\n",
            "  1.96987294e-05 3.46241141e-05 3.75799282e-05 1.13329392e-04\n",
            "  1.01239537e-04 2.20730537e-04 1.03405400e-04 7.00424280e-05\n",
            "  7.26799553e-05 1.15771771e-04 5.73045145e-05 6.56926204e-05\n",
            "  4.65327830e-05 1.07741798e-04 1.21452460e-04 5.76875209e-05\n",
            "  7.01592217e-05 1.41807192e-04 1.00250232e-04 2.74584687e-04\n",
            "  1.98471796e-04 5.14645762e-05 9.67726446e-05 4.71975036e-05\n",
            "  3.46396409e-05 3.41118030e-05 1.45949918e-04 1.12146306e-04\n",
            "  1.23993494e-04 1.18086129e-04 9.68397653e-05 6.43576568e-05\n",
            "  1.18753007e-04 1.77217749e-04 4.85495111e-05 2.31395970e-04\n",
            "  1.02449521e-04 5.94245139e-05 1.02893966e-04 5.58955471e-05\n",
            "  5.52252241e-05 5.13286541e-05 1.56039750e-05 7.09726301e-05\n",
            "  3.51095478e-05 1.27503532e-04 7.17438597e-05 5.66272865e-05\n",
            "  1.08331347e-04 3.56743840e-05 7.66950106e-05 7.71613850e-05\n",
            "  8.26110190e-05 5.52588353e-05 8.30286808e-05 5.07941731e-05\n",
            "  3.09731950e-05 1.11332381e-04 3.77394645e-05 6.23961459e-05\n",
            "  9.27637157e-05 4.57285569e-05 4.09872155e-05 2.58465643e-05\n",
            "  7.99051923e-05 4.29079264e-05 4.70530613e-05 2.74315462e-05\n",
            "  7.71415216e-05 1.08307584e-04 4.53524444e-05 7.30300671e-05\n",
            "  2.50014673e-05 5.84831396e-05 7.32432163e-05 7.30119573e-05\n",
            "  4.10018365e-05 5.25466276e-05 4.04770719e-04 5.50889854e-05\n",
            "  1.60263284e-04 8.51164077e-05 1.35573253e-04 5.98288752e-05\n",
            "  4.37382732e-05 4.82898613e-05 2.25387885e-05 5.43056085e-05\n",
            "  6.79115401e-05 9.01700259e-05 4.69897423e-05 4.87459911e-05\n",
            "  4.21828772e-05 8.21977374e-05 1.55486210e-04 1.93936812e-05\n",
            "  1.76479531e-04 5.32771373e-05 1.40520191e-04 2.96431554e-05\n",
            "  7.94921725e-05 8.12151557e-05 7.23864505e-05 1.17032396e-04\n",
            "  5.91729695e-05 6.25995090e-05 5.09107085e-05 4.77649664e-05\n",
            "  2.93805952e-05 3.72669347e-05 6.73347386e-05 6.63696919e-05\n",
            "  8.70690128e-05 4.26455335e-05 7.08999069e-05 3.07995288e-05\n",
            "  2.27766486e-05 3.97961703e-05 3.95440911e-05 4.31812805e-05\n",
            "  4.23690653e-05 1.39348078e-04 4.11845358e-05 3.26908266e-05\n",
            "  2.56639960e-05 4.06777144e-05 7.98256733e-05 1.70027648e-04\n",
            "  2.09921680e-04 1.10204608e-04 1.46261053e-04 1.07461550e-04\n",
            "  1.21458128e-04 5.85669732e-05 5.53350910e-05 1.04846440e-04\n",
            "  1.19998229e-04 1.71518972e-04 2.48501543e-04 1.49684842e-04\n",
            "  7.81665949e-05 5.00428905e-05 8.10036800e-05 3.04610148e-04\n",
            "  1.67503080e-04 1.36891947e-04 3.59763726e-05 1.27737570e-04\n",
            "  8.27741096e-05 8.21414724e-05 1.19711229e-04 4.69633116e-04\n",
            "  5.11301514e-05 3.47449495e-05 3.90395835e-05 2.11558345e-05\n",
            "  1.79164505e-04 2.87484254e-05 1.90657433e-04 8.93672695e-05\n",
            "  6.56744596e-05 3.27144044e-05 4.67374994e-05 2.83129266e-05\n",
            "  2.93956164e-05 8.84519613e-05 2.61318910e-05 3.76592907e-05\n",
            "  1.45360536e-04 3.50981682e-05 2.61664041e-04 6.70216468e-05\n",
            "  7.07318104e-05 9.34499112e-05 2.40362024e-05 2.27371493e-05\n",
            "  3.62495157e-05 2.27104611e-04 1.30700096e-01 6.27778427e-05\n",
            "  2.63020338e-05 6.07773000e-05 7.88486650e-05 1.63918221e-03\n",
            "  1.44463207e-04 3.11198164e-05 4.54654102e-04 7.16965296e-05\n",
            "  7.77280211e-01 3.68258043e-05 9.78583921e-05 5.56243467e-05\n",
            "  1.72433152e-04 8.48813288e-05 6.12368676e-05 4.82722753e-05\n",
            "  1.17409014e-04 5.44481118e-05 6.85896302e-05 1.13519447e-04\n",
            "  8.11707141e-05 1.22965110e-04 6.24400127e-05 9.31290051e-05\n",
            "  1.88027829e-04 1.93788248e-04 7.61675037e-05 9.35359494e-05\n",
            "  1.21607758e-04 4.62866992e-05 4.79950140e-05 6.39839200e-05\n",
            "  6.90330489e-05 6.63061146e-05 7.21618926e-05 1.75538211e-04\n",
            "  1.08694789e-04 5.05790158e-05 9.32664989e-05 1.32740082e-04\n",
            "  4.87139696e-05 4.11580768e-05 9.84417129e-05 5.52578349e-05\n",
            "  4.74254957e-05 8.32413207e-05 9.27846777e-05 3.88733679e-05\n",
            "  2.77084073e-05 5.35571708e-05 2.02742049e-05 4.83642943e-05\n",
            "  4.37718227e-05 1.33483351e-04 6.16145990e-05 8.83518005e-05\n",
            "  3.08103539e-04 4.27916275e-05 1.01676596e-04 5.76002203e-05\n",
            "  1.58111070e-04 3.35847799e-05 5.77563878e-05 8.98588405e-05\n",
            "  6.29271599e-05 4.65079393e-05 3.48287831e-05 2.89233794e-05\n",
            "  1.79105395e-04 3.90871573e-05 1.65843867e-05 5.51438570e-05\n",
            "  2.87580515e-05 3.77562392e-05 2.25783297e-05 2.13250951e-05\n",
            "  5.72751742e-05 4.61647614e-05 3.14755707e-05 3.16172664e-05\n",
            "  5.07645309e-05 1.61943783e-04 4.83857912e-05 9.49675232e-05\n",
            "  8.76238701e-05 9.87053136e-05 9.17097423e-05 3.35560791e-04\n",
            "  3.21118605e-05 7.35343638e-05 3.76189782e-05 9.47745430e-05\n",
            "  1.12280293e-04 1.19383221e-04 1.09739321e-05 8.93921606e-05\n",
            "  5.92910292e-05 1.26560291e-04 1.47651590e-04 6.65231128e-05\n",
            "  7.01251702e-05 6.38276542e-05 7.09689702e-05 2.48578581e-04\n",
            "  5.19031018e-05 5.63516223e-05 7.48078528e-05 1.01820697e-04\n",
            "  6.83061953e-05 7.16115246e-05 3.97622171e-05 8.70803051e-05\n",
            "  9.18415535e-05 5.48204953e-05 5.68632313e-05 1.26307321e-04\n",
            "  9.58065211e-05 3.51653762e-05 7.13495538e-05 4.03261874e-05\n",
            "  4.72853135e-05 7.67440288e-05 9.59924510e-05 4.02648911e-05\n",
            "  5.35830186e-05 7.53160930e-05 2.91467411e-04 2.95008758e-05\n",
            "  5.44876966e-05 5.23436647e-05 1.06659551e-04 2.77221407e-04\n",
            "  1.46394741e-04 7.68118261e-05 1.46136823e-04 8.43923553e-05\n",
            "  3.97460281e-05 9.95869268e-05 8.45312170e-05 7.31295149e-05\n",
            "  8.37815387e-05 7.48232633e-05 8.31522993e-05 9.51550028e-05\n",
            "  7.18185474e-05 1.29821303e-04 2.70309072e-04 5.69333424e-05\n",
            "  2.24667037e-05 1.55825401e-04 8.87211208e-05 1.44161808e-04\n",
            "  1.17961084e-04 6.79409495e-05 9.88961183e-05 7.34831920e-05\n",
            "  9.71156478e-05 1.84091798e-04 4.41653465e-05 3.91156827e-05\n",
            "  7.31747932e-05 1.19381628e-04 1.30446424e-04 6.64713007e-05\n",
            "  5.57056228e-05 6.09617855e-05 2.48468394e-04 1.04337239e-04\n",
            "  2.64815626e-05 1.66176585e-04 2.16125409e-04 8.56362021e-05\n",
            "  9.17335346e-05 1.52204811e-04 5.15005122e-05 1.30953485e-04\n",
            "  9.55719879e-05 7.14025737e-05 1.27953143e-04 5.94479789e-05\n",
            "  9.38643498e-05 5.67675452e-05 5.27654738e-05 9.60298130e-05\n",
            "  5.48864627e-05 7.41567055e-05 4.43747995e-05 4.98036461e-05\n",
            "  8.23504233e-05 1.19690223e-04 1.66263286e-04 2.37430038e-04\n",
            "  1.35703114e-04 9.82779311e-05 1.37988100e-04 4.94398526e-04\n",
            "  6.81850725e-05 5.20568210e-05 2.01785399e-04 1.18285403e-04\n",
            "  4.81339484e-05 2.07740832e-05 4.65110425e-05 6.72566312e-05\n",
            "  1.58702504e-04 4.79015907e-05 2.97724600e-05 6.48976275e-05\n",
            "  6.73696777e-05 1.26672589e-04 6.54440664e-05 6.95170384e-05\n",
            "  6.09387062e-05 1.30033935e-04 9.89286636e-05 7.93703657e-05\n",
            "  7.23749254e-05 4.49850086e-05 7.12411711e-05 6.60767837e-05\n",
            "  1.12524584e-04 5.66638009e-05 1.63089455e-04 6.94542905e-05\n",
            "  1.09928435e-04 1.01904137e-04 1.04663319e-04 1.27265317e-04\n",
            "  1.55170535e-04 1.71233769e-04 9.87781023e-05 8.33485610e-05\n",
            "  6.64112304e-05 7.57704038e-05 2.53360253e-04 1.55041096e-04\n",
            "  1.44436475e-04 5.96975588e-05 1.32691988e-04 8.16310567e-05\n",
            "  3.13799574e-05 5.40245492e-05 2.67045125e-05 8.51821023e-05\n",
            "  6.65608677e-05 1.30740358e-04 2.86995819e-05 5.53410027e-05\n",
            "  3.47472014e-05 6.63798201e-05 1.33120659e-04 1.34318238e-04\n",
            "  1.26738072e-04 2.46792595e-04 5.51071134e-05 2.10102749e-04\n",
            "  5.39903995e-05 7.15214337e-05 3.48250149e-04 1.66207639e-04\n",
            "  6.11506766e-05 5.39202665e-05 8.02599388e-05 5.03426854e-05\n",
            "  1.04701750e-04 9.60939433e-05 5.34974424e-05 9.60021571e-05\n",
            "  7.43964847e-05 1.73751090e-04 2.50216963e-05 3.75607233e-05\n",
            "  2.25407002e-05 1.12821261e-04 7.03287733e-05 1.22911282e-04\n",
            "  2.35787549e-04 6.03156041e-05 1.27962165e-04 6.56619959e-05\n",
            "  8.75406768e-05 1.03983206e-04 1.23001577e-04 9.75988150e-05\n",
            "  3.82833932e-05 5.66426788e-05 2.10973347e-04 8.79116415e-05\n",
            "  4.93727821e-05 6.98176809e-05 2.95126811e-04 5.25788600e-05\n",
            "  8.14213636e-05 4.09204658e-05 1.44232486e-04 3.20014660e-05\n",
            "  7.73334759e-05 1.09907996e-04 3.66650274e-05 4.30153959e-05\n",
            "  6.37075500e-05 6.39051359e-05 3.71269161e-05 3.65879561e-04\n",
            "  9.92219429e-05 8.25022144e-05 5.58990650e-05 4.18380478e-05\n",
            "  6.70969821e-05 5.17389744e-05 5.12627084e-05 7.74789733e-05\n",
            "  2.13121966e-04 1.40133023e-04 8.59555439e-05 1.91902262e-04\n",
            "  8.54700775e-05 6.36051991e-05 1.64938192e-05 1.09493500e-04\n",
            "  1.03059530e-04 7.54326247e-05 9.10667150e-05 4.33304085e-05\n",
            "  7.68898099e-05 4.07228981e-05 1.74698333e-04 1.18622847e-04\n",
            "  8.30621066e-05 1.05998814e-04 6.32842202e-05 1.28737840e-04\n",
            "  1.03875172e-04 5.44808354e-05 1.55968723e-04 4.45597798e-05\n",
            "  2.87516887e-05 6.72261085e-05 7.35283393e-05 1.32511399e-04\n",
            "  3.48806716e-05 5.29929057e-05 4.43627796e-05 4.23347337e-05\n",
            "  7.76190500e-05 1.08910193e-04 1.74399858e-04 6.57091005e-05\n",
            "  1.60233787e-04 5.03194969e-05 1.23528225e-04 3.97321601e-05\n",
            "  1.14434559e-04 4.64410114e-05 2.02312396e-04 9.50847025e-05\n",
            "  1.19435826e-04 6.83904800e-05 2.54213432e-04 8.59342326e-05\n",
            "  1.86456426e-04 6.94968912e-05 8.67245180e-05 6.67766581e-05\n",
            "  5.65061782e-05 5.74342921e-05 6.59454599e-05 8.87228089e-05\n",
            "  3.27931812e-05 7.34182613e-05 2.92327459e-05 7.40675096e-05\n",
            "  5.25763535e-05 7.48972961e-05 8.76812192e-05 7.01101890e-05\n",
            "  4.12826521e-05 1.80098490e-04 1.04777777e-04 4.88383557e-05\n",
            "  1.03607061e-04 8.11762875e-05 1.27852138e-04 5.58955471e-05\n",
            "  4.96682260e-05 5.53028040e-05 1.35674913e-04 1.13248578e-04\n",
            "  6.46078843e-05 1.77313763e-04 1.14977796e-04 1.13325601e-04\n",
            "  1.04946681e-04 1.01824276e-04 6.81891688e-05 9.67963642e-05\n",
            "  3.79871744e-05 5.90226045e-05 2.98205105e-05 4.30046493e-05\n",
            "  4.63950637e-05 6.81840975e-05 3.80948477e-05 9.02582105e-05\n",
            "  2.38019820e-05 3.51340350e-05 3.41050400e-05 1.08931898e-04\n",
            "  9.82146958e-05 2.47724733e-04 7.59617033e-05 7.11036482e-05\n",
            "  9.05068882e-05 4.34807553e-05 8.85795162e-05 9.39197707e-05\n",
            "  1.04080238e-04 5.55114166e-05 3.65398519e-05 1.21331133e-04\n",
            "  8.43632224e-05 6.12625736e-05 2.01484843e-04 2.18455934e-05\n",
            "  3.82119397e-05 5.43912320e-05 1.90142106e-04 1.35610229e-04\n",
            "  3.97666554e-05 1.62162309e-04 5.17872541e-05 1.16715506e-04\n",
            "  3.53066462e-05 6.53485768e-05 2.92919922e-05 1.19139484e-04\n",
            "  7.04430204e-05 6.13827506e-05 7.95245505e-05 6.31129878e-05\n",
            "  5.81823988e-05 1.01727121e-04 1.73991357e-04 9.58919845e-05\n",
            "  2.73684156e-04 7.09436717e-05 7.24254642e-05 4.80638591e-05\n",
            "  1.04024570e-04 1.56340873e-04 4.86259196e-05 5.54949547e-05\n",
            "  1.25087841e-04 3.89499983e-05 3.86898828e-05 1.84287841e-04\n",
            "  9.27962756e-05 9.26955327e-05 2.13729523e-04 8.32822989e-05\n",
            "  7.51541593e-05 7.41521144e-05 1.18731259e-04 1.12586196e-04\n",
            "  4.15151953e-05 3.19615719e-05 1.19532924e-04 6.26964757e-05\n",
            "  1.08712200e-04 1.46243896e-04 6.76096315e-05 9.12691248e-05\n",
            "  8.42124282e-05 6.85382984e-05 8.85648187e-05 1.17501535e-04\n",
            "  2.71857221e-04 1.49289233e-04 1.14101102e-04 5.75589329e-05\n",
            "  3.08140698e-05 1.26496583e-04 6.25505709e-05 1.18367898e-04\n",
            "  5.82270841e-05 1.11180445e-04 1.33450376e-04 5.14098756e-05\n",
            "  6.21404979e-05 5.49026372e-05 3.77171564e-05 6.59697398e-05\n",
            "  1.08977212e-04 8.54522295e-05 4.16388248e-05 1.00919409e-04\n",
            "  1.40756645e-04 6.78428551e-05 1.10219218e-04 1.83267810e-04\n",
            "  5.56233899e-05 9.89613036e-05 7.73205684e-05 5.66593189e-05\n",
            "  5.83814945e-05 8.83864413e-05 6.97084397e-05 5.39660032e-05\n",
            "  1.10672132e-04 7.77286841e-05 7.99856280e-05 8.53317106e-05\n",
            "  1.09554705e-04 5.75796257e-05 3.38079262e-05 2.22206014e-04\n",
            "  4.90476486e-05 1.35600785e-04 7.42138000e-05 9.10562958e-05\n",
            "  9.25819186e-05 1.27717969e-04 8.92579847e-05 8.34698731e-05\n",
            "  1.37266601e-04 7.53661079e-05 4.51810629e-05 2.80949516e-05\n",
            "  8.74256773e-04 9.76374504e-05 4.37587987e-05 4.87874277e-05\n",
            "  9.81572011e-05 7.31815599e-05 9.66511725e-05 1.10178546e-04\n",
            "  1.00481004e-04 4.27820814e-05 9.98872056e-05 7.89869955e-05\n",
            "  2.77186627e-05 1.63474397e-04 3.41798332e-05 4.09900676e-05\n",
            "  4.50583429e-05 1.02186161e-04 6.39635473e-05 7.21203396e-05\n",
            "  6.42276063e-05 4.01991674e-05 1.06166655e-04 3.85960557e-05\n",
            "  2.43244183e-04 7.15617571e-05 7.63797580e-05 9.68716267e-05\n",
            "  1.38760093e-04 1.17779651e-04 1.06355139e-04 5.81827917e-05\n",
            "  4.13961534e-05 3.50389055e-05 5.52869315e-05 1.40010598e-05\n",
            "  6.46725457e-05 3.44734108e-05 1.20459044e-04 8.64049507e-05\n",
            "  2.16105196e-04 1.06975145e-04 7.37368246e-05 5.39280809e-05\n",
            "  8.75886981e-05 5.31048681e-05 1.48753592e-04 5.72898171e-05\n",
            "  7.99772315e-05 7.26915314e-05 2.85177393e-05 1.07772939e-04\n",
            "  1.51999280e-04 4.47350321e-05 6.20217907e-05 6.69691290e-05\n",
            "  1.05020765e-04 4.04067578e-05 6.19098646e-05 5.44621907e-05\n",
            "  7.91061029e-05 5.90195050e-05 6.06945905e-05 6.47707842e-04\n",
            "  8.39754430e-05 1.11857480e-04 6.75773917e-05 1.04003338e-04\n",
            "  5.48791322e-05 9.03126274e-05 7.40446994e-05 8.20075438e-05\n",
            "  5.28723103e-05 7.70515981e-05 7.66578596e-05 9.17096550e-05\n",
            "  5.26013791e-05 9.53654089e-05 3.93125083e-05 1.01864003e-04\n",
            "  6.20922801e-05 1.78233931e-05 2.97386636e-04 4.30959590e-05\n",
            "  9.62780396e-05 8.20432178e-05 1.60299969e-04 1.11060595e-04\n",
            "  1.21661011e-04 6.77205535e-05 1.54123263e-04 1.49535321e-04\n",
            "  2.96575199e-05 8.66876362e-05 9.38775047e-05 7.16851137e-05\n",
            "  6.53350580e-05 1.11152563e-04 3.10368720e-04 7.89795376e-05\n",
            "  3.01004620e-05 4.96389221e-05 1.04721228e-04 6.24515669e-05\n",
            "  8.48682976e-05 4.39237658e-04 4.16693729e-05 4.26335391e-05\n",
            "  4.87738434e-05 2.16826913e-04 6.91457171e-05 1.89233091e-04\n",
            "  1.00599129e-04 8.51750374e-05 8.79314248e-05 8.61697627e-05\n",
            "  8.05375748e-05 1.11921712e-04 1.07521621e-04 1.72872955e-04\n",
            "  3.64707637e-04 9.54439311e-05 8.25636089e-05 1.09790672e-04\n",
            "  1.16111660e-04 1.14557406e-04 1.85897501e-04 5.61547386e-05\n",
            "  8.34515595e-05 4.11618421e-05 6.29549540e-05 1.19609431e-04\n",
            "  7.00048331e-05 6.21809304e-05 7.24896599e-05 5.69569638e-05\n",
            "  1.61500837e-04 1.52791195e-04 1.07317450e-04 2.18259258e-04\n",
            "  4.35898219e-05 6.17545447e-05 1.14877403e-04 5.87652503e-05\n",
            "  4.09738495e-05 5.14444546e-05 1.27000385e-04 1.11957910e-04\n",
            "  8.19277338e-05 1.44492427e-04 2.63422349e-04 9.70084511e-05\n",
            "  1.12425048e-04 9.69811736e-05 1.12208574e-04 9.01256644e-05\n",
            "  6.50262373e-05 1.19025470e-04 9.47448134e-05 3.88089509e-04\n",
            "  3.71211463e-05 3.01854670e-05 1.88949969e-04 3.65019550e-05\n",
            "  2.75237617e-05 3.66732093e-05 4.39531141e-05 5.60244807e-05\n",
            "  9.40853497e-05 3.40118888e-04 1.79683149e-04 1.40401622e-04\n",
            "  5.20534450e-05 1.15146897e-04 7.31019754e-05 5.75008853e-05\n",
            "  1.31246183e-04 1.15611685e-04 1.15982744e-04 7.89976912e-05\n",
            "  7.85776720e-05 1.28005748e-04 7.18994852e-05 3.10201685e-05\n",
            "  4.34464309e-05 7.50631880e-05 5.34429273e-05 4.89847298e-05]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0hxTImpkZshS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "84263e63-df47-4b19-a06d-eaf9cd698410"
      },
      "cell_type": "code",
      "source": [
        "decode_predictions(Y)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('n02129604', 'tiger', 0.7772802),\n",
              "  ('n02123159', 'tiger_cat', 0.1307001),\n",
              "  ('n02127052', 'lynx', 0.0016391822),\n",
              "  ('n04266014', 'space_shuttle', 0.0008742568),\n",
              "  ('n04487394', 'trombone', 0.00064770784)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "metadata": {
        "id": "56lskOoWcRys",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "d8285fcf-a232-4054-ae41-86397de31656"
      },
      "cell_type": "code",
      "source": [
        "# Rede neural identificando imagem\n",
        "X = image.img_to_array(image.load_img(\"./tiger.jpg\", target_size=(299, 299)))\n",
        "\n",
        "# Alterando os valores da matrix de um ranger de 0-255 para -1 a 1\n",
        "X /= 255\n",
        "X -= 0.5\n",
        "X *= 2\n",
        "\n",
        "X = X.reshape([1, X.shape[0], X.shape[1], X.shape[2]])\n",
        "\n",
        "Y = iv3.predict(X)\n",
        "\n",
        "decode_predictions(Y)\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('n02129604', 'tiger', 0.7772802),\n",
              "  ('n02123159', 'tiger_cat', 0.1307001),\n",
              "  ('n02127052', 'lynx', 0.0016391822),\n",
              "  ('n04266014', 'space_shuttle', 0.0008742568),\n",
              "  ('n04487394', 'trombone', 0.00064770784)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "metadata": {
        "id": "BwP73pvydSML",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Ataques Adversarios**\n",
        "\n",
        "Podemos manipular esta entrada desta rede neural\n",
        "\n",
        "Como podemos gerar este tipo de imagem, para manipular esta rede neural\n",
        "\n",
        "nos vamos utilizar um parametro de ajuste nos parametros dos pixel da imagem de entrada."
      ]
    },
    {
      "metadata": {
        "id": "0_uNRIRSdRC8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7090
        },
        "outputId": "83e5418e-7300-40bd-9e80-69ac9c7444f0"
      },
      "cell_type": "code",
      "source": [
        "# Criando uma forma de manipular esta rede\n",
        "inp_layer = iv3.layers[0].input\n",
        "out_layer = iv3.layers[-1].output\n",
        "\n",
        "# a classe limão esta clasificada com 951\n",
        "target_class = 951\n",
        "\n",
        "loss = out_layer[0, target_class]\n",
        "\n",
        "grad = K.gradients(loss, inp_layer)[0]\n",
        "\n",
        "optimize_gradient = K.function([inp_layer, K.learning_phase()], [grad, loss])\n",
        "\n",
        "\n",
        "# criando o loop\n",
        "\n",
        "adv = np.copy(X)\n",
        "\n",
        "\n",
        "# valor de pertubação que não pode ser ultrapaçado\n",
        "# esta referencia é para deixar a imagem gerada imperceptivel \n",
        "# a nos humanos.\n",
        "\n",
        "# na manipulação do pixel não pode ultrapassar isso\n",
        "\n",
        "pert = 0.01\n",
        "\n",
        "max_pert = X + 0.01\n",
        "min_pert = X - 0.01\n",
        "\n",
        "# -----------------\n",
        "\n",
        "cost = 0.0\n",
        "\n",
        "while cost < 0.95:\n",
        "  \n",
        "  gr, cost = optimize_gradient([adv, 0]) # ,0 modo teste \n",
        "  \n",
        "  adv += gr\n",
        "  \n",
        "  # os valores de saturação não pode ser maiores que estas variaveis\n",
        "  \n",
        "  adv = np.clip(min_pert, max_pert)\n",
        "  \n",
        "  \n",
        "  print(\"Lemon cost: \", cost)\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target cost:  0.00021825926\n",
            "Target cost:  0.00021935662\n",
            "Target cost:  0.00022047812\n",
            "Target cost:  0.00022159981\n",
            "Target cost:  0.00022273979\n",
            "Target cost:  0.00022389606\n",
            "Target cost:  0.00022506036\n",
            "Target cost:  0.0002262199\n",
            "Target cost:  0.00022738863\n",
            "Target cost:  0.00022857363\n",
            "Target cost:  0.00022977876\n",
            "Target cost:  0.00023101059\n",
            "Target cost:  0.00023225491\n",
            "Target cost:  0.0002335114\n",
            "Target cost:  0.00023479767\n",
            "Target cost:  0.00023607869\n",
            "Target cost:  0.00023734874\n",
            "Target cost:  0.00023862535\n",
            "Target cost:  0.00023991693\n",
            "Target cost:  0.00024120984\n",
            "Target cost:  0.00024249744\n",
            "Target cost:  0.0002437988\n",
            "Target cost:  0.0002451005\n",
            "Target cost:  0.00024642845\n",
            "Target cost:  0.0002477531\n",
            "Target cost:  0.00024907436\n",
            "Target cost:  0.0002503682\n",
            "Target cost:  0.00025162337\n",
            "Target cost:  0.00025288478\n",
            "Target cost:  0.00025416116\n",
            "Target cost:  0.00025543376\n",
            "Target cost:  0.0002567071\n",
            "Target cost:  0.00025800182\n",
            "Target cost:  0.0002592999\n",
            "Target cost:  0.0002606057\n",
            "Target cost:  0.00026190747\n",
            "Target cost:  0.00026322852\n",
            "Target cost:  0.00026456467\n",
            "Target cost:  0.00026591014\n",
            "Target cost:  0.0002672781\n",
            "Target cost:  0.00026864518\n",
            "Target cost:  0.0002700248\n",
            "Target cost:  0.00027140672\n",
            "Target cost:  0.00027280647\n",
            "Target cost:  0.0002741922\n",
            "Target cost:  0.00027559255\n",
            "Target cost:  0.00027699396\n",
            "Target cost:  0.0002783904\n",
            "Target cost:  0.00027977754\n",
            "Target cost:  0.0002811801\n",
            "Target cost:  0.00028260952\n",
            "Target cost:  0.0002840536\n",
            "Target cost:  0.00028548896\n",
            "Target cost:  0.0002869355\n",
            "Target cost:  0.00028840115\n",
            "Target cost:  0.00028987374\n",
            "Target cost:  0.00029136066\n",
            "Target cost:  0.00029288422\n",
            "Target cost:  0.00029437742\n",
            "Target cost:  0.0002958695\n",
            "Target cost:  0.00029737462\n",
            "Target cost:  0.00029887795\n",
            "Target cost:  0.0003003964\n",
            "Target cost:  0.00030193705\n",
            "Target cost:  0.00030349437\n",
            "Target cost:  0.0003050875\n",
            "Target cost:  0.0003067183\n",
            "Target cost:  0.0003083729\n",
            "Target cost:  0.00031001764\n",
            "Target cost:  0.00031168837\n",
            "Target cost:  0.00031336787\n",
            "Target cost:  0.0003150666\n",
            "Target cost:  0.0003167628\n",
            "Target cost:  0.00031847873\n",
            "Target cost:  0.00032020645\n",
            "Target cost:  0.0003219557\n",
            "Target cost:  0.00032368826\n",
            "Target cost:  0.00032541808\n",
            "Target cost:  0.00032718308\n",
            "Target cost:  0.00032896842\n",
            "Target cost:  0.00033076855\n",
            "Target cost:  0.0003325628\n",
            "Target cost:  0.00033435994\n",
            "Target cost:  0.00033615108\n",
            "Target cost:  0.00033794885\n",
            "Target cost:  0.00033973996\n",
            "Target cost:  0.00034153208\n",
            "Target cost:  0.0003433316\n",
            "Target cost:  0.0003451551\n",
            "Target cost:  0.00034699458\n",
            "Target cost:  0.00034882943\n",
            "Target cost:  0.00035066795\n",
            "Target cost:  0.00035254523\n",
            "Target cost:  0.00035445235\n",
            "Target cost:  0.00035636488\n",
            "Target cost:  0.00035829443\n",
            "Target cost:  0.0003602487\n",
            "Target cost:  0.00036221588\n",
            "Target cost:  0.00036417943\n",
            "Target cost:  0.0003661716\n",
            "Target cost:  0.0003681853\n",
            "Target cost:  0.00037020506\n",
            "Target cost:  0.00037223205\n",
            "Target cost:  0.00037428227\n",
            "Target cost:  0.00037632778\n",
            "Target cost:  0.00037838554\n",
            "Target cost:  0.00038047016\n",
            "Target cost:  0.00038255783\n",
            "Target cost:  0.00038465302\n",
            "Target cost:  0.000386755\n",
            "Target cost:  0.00038884638\n",
            "Target cost:  0.00039093764\n",
            "Target cost:  0.00039304246\n",
            "Target cost:  0.00039516814\n",
            "Target cost:  0.00039731275\n",
            "Target cost:  0.00039946407\n",
            "Target cost:  0.00040163423\n",
            "Target cost:  0.0004038367\n",
            "Target cost:  0.00040608298\n",
            "Target cost:  0.0004083415\n",
            "Target cost:  0.0004106212\n",
            "Target cost:  0.00041291025\n",
            "Target cost:  0.0004152169\n",
            "Target cost:  0.0004175333\n",
            "Target cost:  0.0004198615\n",
            "Target cost:  0.00042220514\n",
            "Target cost:  0.00042457125\n",
            "Target cost:  0.00042694123\n",
            "Target cost:  0.00042930018\n",
            "Target cost:  0.00043168262\n",
            "Target cost:  0.00043411079\n",
            "Target cost:  0.00043654194\n",
            "Target cost:  0.00043899385\n",
            "Target cost:  0.00044143153\n",
            "Target cost:  0.00044381103\n",
            "Target cost:  0.00044621475\n",
            "Target cost:  0.00044863246\n",
            "Target cost:  0.00045110224\n",
            "Target cost:  0.0004535918\n",
            "Target cost:  0.00045611575\n",
            "Target cost:  0.0004586785\n",
            "Target cost:  0.00046126416\n",
            "Target cost:  0.00046389215\n",
            "Target cost:  0.0004665631\n",
            "Target cost:  0.00046926358\n",
            "Target cost:  0.00047198962\n",
            "Target cost:  0.00047476322\n",
            "Target cost:  0.00047757514\n",
            "Target cost:  0.00048040412\n",
            "Target cost:  0.00048327557\n",
            "Target cost:  0.00048618348\n",
            "Target cost:  0.00048916595\n",
            "Target cost:  0.00049218215\n",
            "Target cost:  0.0004952103\n",
            "Target cost:  0.00049825775\n",
            "Target cost:  0.0005013267\n",
            "Target cost:  0.0005044106\n",
            "Target cost:  0.0005075368\n",
            "Target cost:  0.00051068503\n",
            "Target cost:  0.0005138564\n",
            "Target cost:  0.0005170394\n",
            "Target cost:  0.0005202374\n",
            "Target cost:  0.0005234818\n",
            "Target cost:  0.0005267889\n",
            "Target cost:  0.00053009257\n",
            "Target cost:  0.00053343084\n",
            "Target cost:  0.00053681846\n",
            "Target cost:  0.0005402731\n",
            "Target cost:  0.0005437429\n",
            "Target cost:  0.00054723886\n",
            "Target cost:  0.00055075315\n",
            "Target cost:  0.00055432325\n",
            "Target cost:  0.00055791205\n",
            "Target cost:  0.000561501\n",
            "Target cost:  0.00056510384\n",
            "Target cost:  0.0005687957\n",
            "Target cost:  0.0005725777\n",
            "Target cost:  0.0005763679\n",
            "Target cost:  0.000580205\n",
            "Target cost:  0.00058418006\n",
            "Target cost:  0.0005882299\n",
            "Target cost:  0.0005922646\n",
            "Target cost:  0.00059632864\n",
            "Target cost:  0.0006004257\n",
            "Target cost:  0.0006045808\n",
            "Target cost:  0.00060882425\n",
            "Target cost:  0.00061302225\n",
            "Target cost:  0.0006172636\n",
            "Target cost:  0.00062157016\n",
            "Target cost:  0.00062597287\n",
            "Target cost:  0.00063034263\n",
            "Target cost:  0.00063458504\n",
            "Target cost:  0.0006388152\n",
            "Target cost:  0.00064310513\n",
            "Target cost:  0.00064743904\n",
            "Target cost:  0.00065180694\n",
            "Target cost:  0.0006562142\n",
            "Target cost:  0.00066068425\n",
            "Target cost:  0.0006652412\n",
            "Target cost:  0.0006698164\n",
            "Target cost:  0.0006744276\n",
            "Target cost:  0.00067909603\n",
            "Target cost:  0.00068387634\n",
            "Target cost:  0.0006886458\n",
            "Target cost:  0.0006934551\n",
            "Target cost:  0.000698299\n",
            "Target cost:  0.00070319284\n",
            "Target cost:  0.00070811796\n",
            "Target cost:  0.0007130904\n",
            "Target cost:  0.000718095\n",
            "Target cost:  0.00072314683\n",
            "Target cost:  0.00072817696\n",
            "Target cost:  0.00073322264\n",
            "Target cost:  0.0007383031\n",
            "Target cost:  0.0007434219\n",
            "Target cost:  0.00074859225\n",
            "Target cost:  0.0007538563\n",
            "Target cost:  0.00075917697\n",
            "Target cost:  0.00076462835\n",
            "Target cost:  0.00077025325\n",
            "Target cost:  0.0007760194\n",
            "Target cost:  0.00078188936\n",
            "Target cost:  0.00078783743\n",
            "Target cost:  0.0007938744\n",
            "Target cost:  0.0008000102\n",
            "Target cost:  0.0008062035\n",
            "Target cost:  0.0008124491\n",
            "Target cost:  0.0008186856\n",
            "Target cost:  0.00082497793\n",
            "Target cost:  0.0008313295\n",
            "Target cost:  0.00083774474\n",
            "Target cost:  0.0008442106\n",
            "Target cost:  0.0008507298\n",
            "Target cost:  0.0008573992\n",
            "Target cost:  0.0008641639\n",
            "Target cost:  0.00087098556\n",
            "Target cost:  0.0008778422\n",
            "Target cost:  0.0008847837\n",
            "Target cost:  0.0008918212\n",
            "Target cost:  0.00089918287\n",
            "Target cost:  0.00090662035\n",
            "Target cost:  0.00091408513\n",
            "Target cost:  0.0009216398\n",
            "Target cost:  0.000929234\n",
            "Target cost:  0.00093687535\n",
            "Target cost:  0.000944596\n",
            "Target cost:  0.00095239904\n",
            "Target cost:  0.0009603057\n",
            "Target cost:  0.0009685105\n",
            "Target cost:  0.0009768532\n",
            "Target cost:  0.0009852881\n",
            "Target cost:  0.0009938292\n",
            "Target cost:  0.001002437\n",
            "Target cost:  0.0010111434\n",
            "Target cost:  0.0010201174\n",
            "Target cost:  0.001029101\n",
            "Target cost:  0.0010382521\n",
            "Target cost:  0.0010474329\n",
            "Target cost:  0.0010566664\n",
            "Target cost:  0.0010660436\n",
            "Target cost:  0.0010756265\n",
            "Target cost:  0.0010854824\n",
            "Target cost:  0.0010956846\n",
            "Target cost:  0.0011060935\n",
            "Target cost:  0.0011167817\n",
            "Target cost:  0.0011272749\n",
            "Target cost:  0.0011380519\n",
            "Target cost:  0.0011492474\n",
            "Target cost:  0.0011607023\n",
            "Target cost:  0.0011723116\n",
            "Target cost:  0.0011842359\n",
            "Target cost:  0.0011962648\n",
            "Target cost:  0.001208366\n",
            "Target cost:  0.0012207495\n",
            "Target cost:  0.0012333479\n",
            "Target cost:  0.0012462933\n",
            "Target cost:  0.0012595364\n",
            "Target cost:  0.0012728275\n",
            "Target cost:  0.0012862677\n",
            "Target cost:  0.0012996937\n",
            "Target cost:  0.0013131473\n",
            "Target cost:  0.0013269059\n",
            "Target cost:  0.0013411402\n",
            "Target cost:  0.0013557395\n",
            "Target cost:  0.0013705295\n",
            "Target cost:  0.0013854259\n",
            "Target cost:  0.001400674\n",
            "Target cost:  0.0014163073\n",
            "Target cost:  0.0014323539\n",
            "Target cost:  0.0014487515\n",
            "Target cost:  0.0014654663\n",
            "Target cost:  0.0014829764\n",
            "Target cost:  0.0015009191\n",
            "Target cost:  0.0015196148\n",
            "Target cost:  0.0015386116\n",
            "Target cost:  0.0015578136\n",
            "Target cost:  0.001577402\n",
            "Target cost:  0.0015974742\n",
            "Target cost:  0.0016182147\n",
            "Target cost:  0.0016391453\n",
            "Target cost:  0.0016604591\n",
            "Target cost:  0.0016821478\n",
            "Target cost:  0.0017046733\n",
            "Target cost:  0.0017274488\n",
            "Target cost:  0.0017505661\n",
            "Target cost:  0.0017743503\n",
            "Target cost:  0.0017985252\n",
            "Target cost:  0.0018227377\n",
            "Target cost:  0.0018472759\n",
            "Target cost:  0.0018722095\n",
            "Target cost:  0.0018979686\n",
            "Target cost:  0.0019247065\n",
            "Target cost:  0.0019518641\n",
            "Target cost:  0.001979791\n",
            "Target cost:  0.0020075385\n",
            "Target cost:  0.0020353815\n",
            "Target cost:  0.0020635168\n",
            "Target cost:  0.002091625\n",
            "Target cost:  0.0021200022\n",
            "Target cost:  0.0021494073\n",
            "Target cost:  0.0021793908\n",
            "Target cost:  0.0022097481\n",
            "Target cost:  0.0022404413\n",
            "Target cost:  0.0022720562\n",
            "Target cost:  0.002304319\n",
            "Target cost:  0.0023374595\n",
            "Target cost:  0.002371702\n",
            "Target cost:  0.0024069224\n",
            "Target cost:  0.0024432414\n",
            "Target cost:  0.0024805253\n",
            "Target cost:  0.0025189866\n",
            "Target cost:  0.0025593915\n",
            "Target cost:  0.0026012533\n",
            "Target cost:  0.002643353\n",
            "Target cost:  0.0026870598\n",
            "Target cost:  0.0027327198\n",
            "Target cost:  0.0027797134\n",
            "Target cost:  0.0028277796\n",
            "Target cost:  0.0028770727\n",
            "Target cost:  0.0029266127\n",
            "Target cost:  0.0029773647\n",
            "Target cost:  0.0030294345\n",
            "Target cost:  0.0030824225\n",
            "Target cost:  0.0031363147\n",
            "Target cost:  0.0031909815\n",
            "Target cost:  0.0032480482\n",
            "Target cost:  0.00330652\n",
            "Target cost:  0.0033668734\n",
            "Target cost:  0.0034333116\n",
            "Target cost:  0.0035013051\n",
            "Target cost:  0.003571448\n",
            "Target cost:  0.0036416375\n",
            "Target cost:  0.0037133822\n",
            "Target cost:  0.0037903718\n",
            "Target cost:  0.0038703652\n",
            "Target cost:  0.0039503216\n",
            "Target cost:  0.0040341234\n",
            "Target cost:  0.0041254335\n",
            "Target cost:  0.0042182626\n",
            "Target cost:  0.0043190997\n",
            "Target cost:  0.004420171\n",
            "Target cost:  0.004521909\n",
            "Target cost:  0.004613079\n",
            "Target cost:  0.004707009\n",
            "Target cost:  0.004845276\n",
            "Target cost:  0.0049672015\n",
            "Target cost:  0.005105992\n",
            "Target cost:  0.005245141\n",
            "Target cost:  0.0053955875\n",
            "Target cost:  0.0055409716\n",
            "Target cost:  0.0057087014\n",
            "Target cost:  0.0058720605\n",
            "Target cost:  0.0060468125\n",
            "Target cost:  0.0061957957\n",
            "Target cost:  0.0063639316\n",
            "Target cost:  0.0065383604\n",
            "Target cost:  0.0067874636\n",
            "Target cost:  0.006982239\n",
            "Target cost:  0.0071615395\n",
            "Target cost:  0.0073057446\n",
            "Target cost:  0.007607207\n",
            "Target cost:  0.00783338\n",
            "Target cost:  0.008280423\n",
            "Target cost:  0.008561741\n",
            "Target cost:  0.008962429\n",
            "Target cost:  0.009198274\n",
            "Target cost:  0.009656015\n",
            "Target cost:  0.009902975\n",
            "Target cost:  0.010440204\n",
            "Target cost:  0.010823476\n",
            "Target cost:  0.011525632\n",
            "Target cost:  0.011903048\n",
            "Target cost:  0.0128604015\n",
            "Target cost:  0.013570176\n",
            "Target cost:  0.014362434\n",
            "Target cost:  0.015080898\n",
            "Target cost:  0.015886234\n",
            "Target cost:  0.016235314\n",
            "Target cost:  0.018293645\n",
            "Target cost:  0.017950783\n",
            "Target cost:  0.018365936\n",
            "Target cost:  0.021715296\n",
            "Target cost:  0.023204254\n",
            "Target cost:  0.021622082\n",
            "Target cost:  0.02612541\n",
            "Target cost:  0.029949313\n",
            "Target cost:  0.033833653\n",
            "Target cost:  0.03752134\n",
            "Target cost:  0.046638712\n",
            "Target cost:  0.05291024\n",
            "Target cost:  0.072969034\n",
            "Target cost:  0.06969898\n",
            "Target cost:  0.106465586\n",
            "Target cost:  0.1266144\n",
            "Target cost:  0.2306353\n",
            "Target cost:  0.0908936\n",
            "Target cost:  0.4219767\n",
            "Target cost:  0.21396524\n",
            "Target cost:  0.5734705\n",
            "Target cost:  0.9339844\n",
            "Target cost:  0.99630463\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k7EAUoFhojW8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# para abrir o help de uma função coloque (?) apos ela. \n",
        "np.clip?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DTwdj1YRmVRB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "A Rede chego a  **0.99630463** de equivalencia de que o tigre é um Limão\n"
      ]
    },
    {
      "metadata": {
        "id": "nhbvdOMbi9aG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reinverter os passos que foi feito antes\n",
        "adv /= 2\n",
        "adv += 0.5\n",
        "adv *= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bmN6M8NcfDeL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "3fe3bc04-6030-484d-94d4-d555b12f48d0"
      },
      "cell_type": "code",
      "source": [
        "print(inp_layer)\n",
        "print(out_layer)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"input_1:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
            "Tensor(\"predictions/Softmax:0\", shape=(?, 1000), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}